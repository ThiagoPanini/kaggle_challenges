{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Libraries\" data-toc-modified-id=\"Libraries-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Libraries</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Functions</a></span></li><li><span><a href=\"#Data-Prep\" data-toc-modified-id=\"Data-Prep-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Prep</a></span></li><li><span><a href=\"#Terrorism-Around-the-World\" data-toc-modified-id=\"Terrorism-Around-the-World-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Terrorism Around the World</a></span></li><li><span><a href=\"#Countries-and-Terrorism\" data-toc-modified-id=\"Countries-and-Terrorism-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Countries and Terrorism</a></span></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>References</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the second part of (link Kaggle), where an extremely important process of understanding the data was carried out in order to go deep into the context and make useful data transformations for later analysis.\n",
    "\n",
    "This second approach intends to tell a story about Terrorism around the world taking the data provided as base. Here, we will apply an exploratory data analysis in order to understand more about terrorists incidents recorded over the years. We will also search for patterns and explanations related to the context and try to tell a story about it.\n",
    "\n",
    "It's important to say that we will do the same data preparation in Part 1 in a simplified way, since we have already understood the process. So, the objective are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Big picture of terrorism around the world and its evolution over the years;\n",
    "* Countries with most incidents recorded;\n",
    "* Countries with highest number of victims;\n",
    "* Create a dashboard for terrorism analysis in some countries;\n",
    "* Incidents that lasted more than 24h (extended = 1);\n",
    "* Major radical groups responsible for terrorist attacks (gname);\n",
    "* Attacks with the highest number of terrorists (nperps);\n",
    "* Create a WordCloud for attributes like summary corp1, target1 and motive;\n",
    "* See wordclouds over the years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T20:06:58.271086Z",
     "start_time": "2019-09-04T20:06:41.542704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopandas\n",
      "  Downloading https://files.pythonhosted.org/packages/21/80/da2a33c9201cd4ce693f4aa6189efc9ef1a48bec1c3b02c3ce9908b07fec/geopandas-0.5.1-py2.py3-none-any.whl (893kB)\n",
      "Collecting fiona (from geopandas)\n",
      "  Downloading https://files.pythonhosted.org/packages/41/9d/63696e7b1de42aad294d4781199a408bec593d8fdb80a2b4a788c911a33b/Fiona-1.8.6.tar.gz (1.7MB)\n",
      "    Complete output from command python setup.py egg_info:\n",
      "    A GDAL API version must be specified. Provide a path to gdal-config using a GDAL_CONFIG environment variable or use a GDAL_VERSION environment variable.\n",
      "    \n",
      "    ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Command \"python setup.py egg_info\" failed with error code 1 in C:\\Users\\thipa\\AppData\\Local\\Temp\\pip-install-debae3g8\\fiona\\\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "try:\n",
    "    import folium\n",
    "except:\n",
    "    !pip install folium\n",
    "from folium.plugins import FastMarkerCluster, Fullscreen, MiniMap, HeatMap, HeatMapWithTime\n",
    "try:\n",
    "    import geopandas as gpd\n",
    "except:\n",
    "    !pip install geopandas\n",
    "from branca.colormap import LinearColormap\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T20:06:58.337875Z",
     "start_time": "2019-09-04T20:06:58.273048Z"
    }
   },
   "outputs": [],
   "source": [
    "def style_function(feature):\n",
    "    \"\"\"\n",
    "    Customize maps\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'fillColor': '#ffaf00',\n",
    "        'color': 'grey',\n",
    "        'weight': 1.5,\n",
    "        'dashArray': '5, 5'\n",
    "    }\n",
    "\n",
    "def highlight_function(feature):\n",
    "    \"\"\"\n",
    "    Customize maps\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'fillColor': '#ffaf00',\n",
    "        'color': 'black',\n",
    "        'weight': 2,\n",
    "        'dashArray': '5, 5'\n",
    "    }\n",
    "\n",
    "def format_spines(ax, right_border=True):\n",
    "    \"\"\"\n",
    "    This function sets up borders from an axis and personalize colors\n",
    "    \n",
    "    Input:\n",
    "        Axis and a flag for deciding or not to plot the right border\n",
    "    Returns:\n",
    "        Plot configuration\n",
    "    \"\"\"    \n",
    "    # Setting up colors\n",
    "    ax.spines['bottom'].set_color('#CCCCCC')\n",
    "    ax.spines['left'].set_color('#CCCCCC')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    if right_border:\n",
    "        ax.spines['right'].set_color('#CCCCCC')\n",
    "    else:\n",
    "        ax.spines['right'].set_color('#FFFFFF')\n",
    "    ax.patch.set_facecolor('#FFFFFF')\n",
    "    \n",
    "def count_plot(feature, df, colors='Blues_d', hue=False, ax=None, title=''):\n",
    "    \"\"\"\n",
    "    This function plots data setting up frequency and percentage in a count plot;\n",
    "    This also sets up borders and personalization.\n",
    "    \n",
    "    Input:\n",
    "        The feature to be counted and the dataframe. Other args are optional.\n",
    "    Returns:\n",
    "        Count plot.\n",
    "    \"\"\"    \n",
    "    # Preparing variables\n",
    "    ncount = len(df)\n",
    "    if hue != False:\n",
    "        ax = sns.countplot(x=feature, data=df, palette=colors, hue=hue, ax=ax, \n",
    "                           order=df[feature].value_counts().index)\n",
    "    else:\n",
    "        ax = sns.countplot(x=feature, data=df, palette=colors, ax=ax,\n",
    "                           order=df[feature].value_counts().index)\n",
    "\n",
    "    # Make twin axis\n",
    "    ax2=ax.twinx()\n",
    "\n",
    "    # Switch so count axis is on right, frequency on left\n",
    "    ax2.yaxis.tick_left()\n",
    "    ax.yaxis.tick_right()\n",
    "\n",
    "    # Also switch the labels over\n",
    "    ax.yaxis.set_label_position('right')\n",
    "    ax2.yaxis.set_label_position('left')\n",
    "    ax2.set_ylabel('Frequency [%]')\n",
    "    frame1 = plt.gca()\n",
    "    frame1.axes.get_yaxis().set_ticks([])\n",
    "\n",
    "    # Setting up borders\n",
    "    format_spines(ax)\n",
    "    format_spines(ax2)\n",
    "\n",
    "    # Setting percentage\n",
    "    for p in ax.patches:\n",
    "        x=p.get_bbox().get_points()[:,0]\n",
    "        y=p.get_bbox().get_points()[1,1]\n",
    "        ax.annotate('{:.1f}%'.format(100.*y/ncount), (x.mean(), y), \n",
    "                ha='center', va='bottom') # set the alignment of the text\n",
    "    \n",
    "    # Final configuration\n",
    "    if not hue:\n",
    "        ax.set_title(df[feature].describe().name + ' Counting plot', size=13, pad=15)\n",
    "    else:\n",
    "        ax.set_title(df[feature].describe().name + ' Counting plot by ' + hue, size=13, pad=15)  \n",
    "    if title != '':\n",
    "        ax.set_title(title)       \n",
    "    plt.tight_layout()\n",
    "    \n",
    "def country_analysis(country_name, data, palette, colors_plot2, color_lineplot):\n",
    "    \"\"\"\n",
    "    This function creates a dashboard with informations of terrorism in a certain country.\n",
    "    Input:\n",
    "        The function receives the name of the country, the dataset and color configuration\n",
    "    Output:\n",
    "        It returns a 4 plot dashboard.\n",
    "    \"\"\"\n",
    "    # Preparing\n",
    "    country = data.query('country_txt == @country_name')\n",
    "    if len(country) == 0:\n",
    "        print('Country did not exists in dataset')\n",
    "        return \n",
    "    country_cities = country.groupby(by='city', as_index=False).count().sort_values('eventid', \n",
    "                                                                                   ascending=False).iloc[:5, :2]\n",
    "    suicide_size = country['suicide'].sum() / len(country)\n",
    "    labels = ['Suicide', 'Not Suicide']\n",
    "    colors = colors_plot2\n",
    "    \n",
    "    country_year = country.groupby(by='iyear', as_index=False).sum().loc[:, ['iyear', 'nkill']]\n",
    "    country_weapon = country.groupby(by='weaptype1_txt', as_index=False).count().sort_values(by='eventid',\n",
    "                                                                                             ascending=False).iloc[:, \n",
    "                                                                                                                   :2]\n",
    "    # Dashboard\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1 - Top 5 terrorism cities\n",
    "    sns.barplot(x='eventid', y='city', data=country_cities, ci=None, palette=palette, ax=axs[0, 0])\n",
    "    format_spines(axs[0, 0], right_border=False)\n",
    "    axs[0, 0].set_title(f'Top 5 {country_name} Cities With Most Terrorism Occurences')\n",
    "    \"\"\"for p in axs[0, 0].patches:\n",
    "        width = p.get_width()\n",
    "        axs[0, 0].text(width-290, p.get_y() + p.get_height() / 2. + 0.10, '{}'.format(int(width)), \n",
    "                ha=\"center\", color='white')\"\"\"\n",
    "    axs[0, 0].set_ylabel('City')\n",
    "    axs[0, 0].set_xlabel('Victims')\n",
    "    \n",
    "    # Plot 2 - Suicide Rate\n",
    "    center_circle = plt.Circle((0,0), 0.75, color='white')\n",
    "    axs[0, 1].pie((suicide_size, 1-suicide_size), labels=labels, colors=colors_plot2, autopct='%1.1f%%')\n",
    "    axs[0, 1].add_artist(center_circle)\n",
    "    format_spines(axs[0, 1], right_border=False)\n",
    "    axs[0, 1].set_title(f'{country_name} Terrorism Suicide Rate')\n",
    "    \n",
    "    # Plot 3 - Victims through the years\n",
    "    sns.lineplot(x='iyear', y='nkill', data=country_year, ax=axs[1, 0], color=color_lineplot)\n",
    "    format_spines(axs[1, 0], right_border=False)\n",
    "    axs[1, 0].set_xlim([1970, 2017])\n",
    "    axs[1, 0].set_title(f'{country_name} Number of Victims Over Time')\n",
    "    axs[1, 0].set_ylabel('Victims')\n",
    "    \n",
    "    # Plot 4 - Terrorism Weapons\n",
    "    sns.barplot(x='weaptype1_txt', y='eventid', data=country_weapon, ci=None, palette=palette, ax=axs[1, 1])\n",
    "    axs[1, 1].set_xticklabels(axs[1, 1].get_xticklabels(), rotation=90)\n",
    "    axs[1, 1].set_xlabel('')\n",
    "    format_spines(axs[1, 1], right_border=False)\n",
    "    axs[1, 1].set_title(f'{country_name} Weapons Used in Attacks')\n",
    "    axs[1, 1].set_ylabel('Count')\n",
    "    \n",
    "    plt.suptitle(f'Terrorism Analysis in {country_name} between 1970 and 2017', size=16)    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T20:06:58.741795Z",
     "start_time": "2019-09-04T20:06:58.342862Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'/home/paninit/Downloads/datasets/globalterrorismdb_0718dist.csv' does not exist: b'/home/paninit/Downloads/datasets/globalterrorismdb_0718dist.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5a0715b7d68b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mterr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/home/paninit/Downloads/datasets/globalterrorismdb_0718dist.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ISO-8859-1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mterr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/home/paninit/Downloads/datasets/globalterrorismdb_0718dist.csv' does not exist: b'/home/paninit/Downloads/datasets/globalterrorismdb_0718dist.csv'"
     ]
    }
   ],
   "source": [
    "terr = pd.read_csv('/home/paninit/Downloads/datasets/globalterrorismdb_0718dist.csv', encoding='ISO-8859-1')\n",
    "terr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T20:06:58.749774Z",
     "start_time": "2019-09-04T20:06:41.579Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filtering attributes\n",
    "atributos_influentes = ['eventid', 'iyear', 'imonth', 'iday', 'extended', 'country_txt', 'region_txt', 'city', \n",
    "                        'latitude', 'longitude', 'specificity', 'summary', 'success', 'suicide', 'attacktype1_txt', \n",
    "                        'targtype1_txt', 'copr1', 'target1', 'natlty1_txt', 'gname', 'motive', 'nperps', \n",
    "                        'weaptype1_txt', 'nkill', 'nkillter', 'nwound', 'nwoundte', 'ishostkid', 'nhostkid']\n",
    "terr_data = terr.loc[:, atributos_influentes]\n",
    "terr_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fill the null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T20:06:58.755759Z",
     "start_time": "2019-09-04T20:06:41.584Z"
    }
   },
   "outputs": [],
   "source": [
    "terr_data.loc[:, 'city'].fillna('Unknown', inplace=True)\n",
    "terr_data.loc[:, 'natlty1_txt'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating new columns for future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T20:06:58.758750Z",
     "start_time": "2019-09-04T20:06:41.588Z"
    }
   },
   "outputs": [],
   "source": [
    "terr_data['iday'] = terr_data['iday'].apply(lambda day: day + 1 if day == 0 else day)\n",
    "terr_data['imonth'] = terr_data['imonth'].apply(lambda month: month + 1 if month == 0 else month)\n",
    "year = terr_data['iyear'].astype(str)\n",
    "month = terr_data['imonth'].astype(str)\n",
    "day = terr_data['iday'].astype(str)\n",
    "terr_data['event_date'] = year + \"/\" + month + \"/\" + day\n",
    "terr_data['event_date'] = pd.to_datetime(terr_data['event_date'])\n",
    "terr_data.iloc[:5, np.r_[:4, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T20:06:58.760744Z",
     "start_time": "2019-09-04T20:06:41.591Z"
    }
   },
   "outputs": [],
   "source": [
    "terr_data['day_of_week'] = terr_data['event_date'].apply(lambda x: x.dayofweek)\n",
    "terr_data['day_of_week_name'] = terr_data['event_date'].dt.day_name()\n",
    "terr_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming some data in order to facilitate the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T20:06:58.761742Z",
     "start_time": "2019-09-04T20:06:41.594Z"
    }
   },
   "outputs": [],
   "source": [
    "terr_data['country_txt'] = terr_data['country_txt'].apply(lambda x: x.replace('United States', \n",
    "                                                                              'United States of America'))\n",
    "terr_data['weaptype1_txt'] = terr_data['weaptype1_txt'].apply(lambda x: x.split()[0] if 'Vehicle' in x.split() else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T23:39:05.666260Z",
     "start_time": "2019-07-09T23:39:05.656807Z"
    }
   },
   "source": [
    "As previousy reported, the above procedures were extremely detailed and explained in Part 1 of this Global Terrorism Data Analysis project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terrorism Around the World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T20:06:58.763736Z",
     "start_time": "2019-09-04T20:06:41.599Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/python-visualization/folium/master/examples/data'\n",
    "world_geo = f'{url}/world-countries.json'\n",
    "json_data = gpd.read_file(f'{url}/world-countries.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T20:06:58.765736Z",
     "start_time": "2019-09-04T20:06:41.604Z"
    }
   },
   "outputs": [],
   "source": [
    "country_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T20:06:58.767726Z",
     "start_time": "2019-09-04T20:06:41.606Z"
    }
   },
   "outputs": [],
   "source": [
    "temp_global[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T20:06:58.768723Z",
     "start_time": "2019-09-04T20:06:41.610Z"
    }
   },
   "outputs": [],
   "source": [
    "country_data = terr_data.groupby(by=['country_txt'], \n",
    "                                 as_index=False).count().sort_values(by='eventid', ascending=False).iloc[:, :2]\n",
    "nkill_data = terr_data.groupby(by=['country_txt'], \n",
    "                                 as_index=False).sum().sort_values(by='eventid', \n",
    "                                                                   ascending=False).loc[:, ['country_txt', 'nkill']]\n",
    "temp_global = json_data.merge(country_data, left_on='name', right_on='country_txt', how='left').fillna(0)\n",
    "global_data = temp_global.merge(nkill_data, left_on='name', right_on='country_txt', how='left').fillna(0)\n",
    "\n",
    "m = folium.Map(\n",
    "    location=[0, 0], \n",
    "    zoom_start=1.75,\n",
    "    tiles='Stamen Terrain'\n",
    ")\n",
    "\n",
    "folium.Choropleth(\n",
    "    geo_data=json_data,\n",
    "    name='Ataques Terroristas',\n",
    "    data=country_data,\n",
    "    columns=['country_txt', 'eventid'],\n",
    "    key_on='feature.properties.name',\n",
    "    fill_color='OrRd',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    nan_fill_color='white',\n",
    "    nan_fill_opacity=0.9,\n",
    "    legend_name='Terrorism Recorded 1970 - 2017',\n",
    "    popup_function='Teste'\n",
    ").add_to(m)\n",
    "\n",
    "Fullscreen(\n",
    "    position='topright',\n",
    "    title='Expand me',\n",
    "    title_cancel='Exit me',\n",
    "    force_separate_button=True\n",
    ").add_to(m)\n",
    "\n",
    "folium.GeoJson(\n",
    "    global_data,\n",
    "    style_function=style_function,\n",
    "    highlight_function=highlight_function,\n",
    "    tooltip=folium.GeoJsonTooltip(fields=['name', 'eventid', 'nkill'],\n",
    "                                  aliases=['Country:', 'Incidents:', 'Victims'],\n",
    "                                  labels=True,\n",
    "                                  sticky=True)\n",
    ").add_to(m)\n",
    "\n",
    "m.save('terrorism_incidents.html')\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, here we can see clearly that Iraq is the country with the highest number of incidents recorded. The map also shows tooltips with the name of the country, number of incidents and total of victims recorded. Another thing that can be said looking at the map is that the Middle East and South Asia are the regions with the highes number of recorded attacks between 1970 and 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very usefull analysis. Let's plot a heatmap to see the density of incidents around the world with a starter zoom in Middle East region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T20:06:58.771716Z",
     "start_time": "2019-09-04T20:06:41.616Z"
    }
   },
   "outputs": [],
   "source": [
    "heat_data = terr_data.groupby(by=['latitude', 'longitude'], \n",
    "                                 as_index=False).count().sort_values(by='eventid', ascending=False).iloc[:, :3]\n",
    "\n",
    "m = folium.Map(\n",
    "    location=[33.312805, 44.361488], \n",
    "    zoom_start=2.5, \n",
    "    tiles='Stamen Toner'\n",
    ")\n",
    "\n",
    "HeatMap(\n",
    "    name='Mapa de Calor',\n",
    "    data=heat_data,\n",
    "    radius=10,\n",
    "    max_zoom=13\n",
    ").add_to(m)\n",
    "\n",
    "Fullscreen(\n",
    "    position='topright',\n",
    "    title='Expand me',\n",
    "    title_cancel='Exit me',\n",
    "    force_separate_button=True\n",
    ").add_to(m)\n",
    "\n",
    "m.save('terrorism_density.html')\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to see the same conclusions as before. Here we can see places with a greater concentration of terrorism. In the next map, we will see the \"evolution\" of terrorism between 1970 and 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T20:06:58.773709Z",
     "start_time": "2019-09-04T20:06:41.620Z"
    }
   },
   "outputs": [],
   "source": [
    "year_list = []\n",
    "for year in terr_data['iyear'].sort_values().unique():\n",
    "    data = terr_data.query('iyear == @year')\n",
    "    data = data.groupby(by=['latitude', 'longitude'], \n",
    "                        as_index=False).count().sort_values(by='eventid', ascending=False).iloc[:, :3]\n",
    "    year_list.append(data.values.tolist())\n",
    "\n",
    "m = folium.Map(\n",
    "    location=[0, 0], \n",
    "    zoom_start=1.5, \n",
    "    tiles='Stamen Toner'\n",
    ")\n",
    "\n",
    "HeatMapWithTime(\n",
    "    name='Terrorism Heatmap',\n",
    "    data=year_list,\n",
    "    radius=9,\n",
    "    index=list(terr_data['iyear'].sort_values().unique())\n",
    ").add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a bar in the bottom where we can select the terrorism records from a specific year between 1970 and 2017. It is important to cross this information with historical facts, wars and incidents. This is extremely usefull!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at the same heatmap vision but this time analysing only data from 2017. We can filter incidents occured by months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T20:06:58.774707Z",
     "start_time": "2019-09-04T20:06:41.625Z"
    }
   },
   "outputs": [],
   "source": [
    "month_index = [\n",
    "    'jan/2017',\n",
    "    'feb/2017',\n",
    "    'mar/2017',\n",
    "    'apr/2017',\n",
    "    'may/2017',\n",
    "    'jun/2017',\n",
    "    'jul/2017',\n",
    "    'aug/2017',\n",
    "    'sep/2017',\n",
    "    'oct/2017',\n",
    "    'nov/2017',\n",
    "    'dec/2017'\n",
    "]\n",
    "\n",
    "month_list = []\n",
    "for month in terr_data.query('iyear==2017')['imonth'].sort_values().unique():\n",
    "    data = terr_data.query('imonth == @month')\n",
    "    data = data.groupby(by=['latitude', 'longitude'], \n",
    "                        as_index=False).sum().sort_values(by='imonth', \n",
    "                                                          ascending=True).loc[:, ['latitude', \n",
    "                                                                                   'longitude', \n",
    "                                                                                   'nkill']]\n",
    "    month_list.append(data.values.tolist())\n",
    "\n",
    "m = folium.Map(\n",
    "    location=[0, 0], \n",
    "    zoom_start=1.5, \n",
    "    tiles='Stamen Toner'\n",
    ")\n",
    "\n",
    "HeatMapWithTime(\n",
    "    name='Mapa de Calor',\n",
    "    data=month_list,\n",
    "    radius=4,\n",
    "    index=month_index\n",
    ").add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Countries and Terrorism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on with our analysis, we can see below the concentration of terrorism by region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T20:06:58.776702Z",
     "start_time": "2019-09-04T20:06:41.633Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "count_plot('region_txt', terr_data, ax=ax, colors='autumn')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "ax.set_title('Distribution of Attacks per Region (1970-2017)', size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have already seen in our first geographical plot, the highest concentration of incidentes recorded are from Middle East & North Africa. The region represents 27.8% of all records between 1970 and 2017. \n",
    "\n",
    "In the next plot, we will make a comparison of this historical data with 2017 data, but this time looking at the top 10 countries if highest nuber of terrorist incidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T20:06:58.778698Z",
     "start_time": "2019-09-04T20:06:41.640Z"
    }
   },
   "outputs": [],
   "source": [
    "country_victims = terr_data.groupby(by='country_txt', as_index=False).sum().sort_values(by='nkill', \n",
    "                                                                      ascending=False).loc[:, ['country_txt', \n",
    "                                                                                               'nkill']]\n",
    "country_victims = country_victims.iloc[:10, :]\n",
    "\n",
    "terr_data_2017 = terr_data.query('iyear == 2017')\n",
    "country_victims_2017 = terr_data_2017.groupby(by='country_txt', as_index=False).sum().sort_values(by='nkill', \n",
    "                                                                      ascending=False).loc[:, ['country_txt', \n",
    "                                                                                               'nkill']]\n",
    "country_victims_2017 = country_victims_2017.iloc[:10, :]\n",
    "country_victims_2017['country_txt'][16] = 'Central African Rep.'\n",
    "country_victims_2017['country_txt'][22] = 'Dem. Rep. Congo'\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15, 7))\n",
    "\n",
    "sns.barplot(x='nkill', y='country_txt', data=country_victims, ci=None,\n",
    "                 palette='autumn', ax=axs[0])\n",
    "sns.barplot(x='nkill', y='country_txt', data=country_victims_2017, ci=None,\n",
    "                 palette='autumn', ax=axs[1])\n",
    "\n",
    "format_spines(axs[0], right_border=False)\n",
    "format_spines(axs[1], right_border=False)\n",
    "axs[0].set_title('Top 10 - Total Victims by Country (1970-2017)')\n",
    "axs[1].set_title('Top 10 - Total Victims by Country (2017)')\n",
    "axs[0].set_ylabel('')\n",
    "axs[1].set_ylabel('')\n",
    "axs[0].set_xlabel('Victims')\n",
    "axs[1].set_xlabel('Victims')\n",
    "\n",
    "for p in axs[0].patches:\n",
    "    width = p.get_width()\n",
    "    axs[0].text(width-4000, p.get_y() + p.get_height() / 2. + 0.10, '{}'.format(int(width)), \n",
    "            ha=\"center\", color='white')\n",
    "\n",
    "for p in axs[1].patches:\n",
    "    width = p.get_width()\n",
    "    axs[1].text(width-300, p.get_y() + p.get_height() / 2. + 0.10, '{}'.format(int(width)), \n",
    "            ha=\"center\", color='white')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the grap above we can see that Iraq and Afghanistan are the countries with most terrorism occurences in 2017 (and also in all period). Colombia, Peru and El Salvador appear in historica data but don't appear in 2017 data maybe because of past conflicts. Let's make a more specific analysis in some countries to see more details.\n",
    "\n",
    "Now I present you the dashboard for country-terrorism relationship analysis. We will see details from Iraq, United States, Nigeria, Colombia and Egypt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T20:06:58.779694Z",
     "start_time": "2019-09-04T20:06:41.646Z"
    }
   },
   "outputs": [],
   "source": [
    "country_analysis(country_name='Iraq', data=terr_data, palette='summer', \n",
    "                 colors_plot2=['crimson', 'green'], color_lineplot='crimson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T20:06:58.781689Z",
     "start_time": "2019-09-04T20:06:41.650Z"
    }
   },
   "outputs": [],
   "source": [
    "country_analysis(country_name='United States of America', data=terr_data, palette='plasma', \n",
    "                 colors_plot2=['crimson', 'navy'], color_lineplot='navy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T20:06:58.782686Z",
     "start_time": "2019-09-04T20:06:41.653Z"
    }
   },
   "outputs": [],
   "source": [
    "country_analysis(country_name='Nigeria', data=terr_data, palette='summer', \n",
    "                 colors_plot2=['crimson', 'green'], color_lineplot='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T20:06:58.784680Z",
     "start_time": "2019-09-04T20:06:41.656Z"
    }
   },
   "outputs": [],
   "source": [
    "country_analysis(country_name='Colombia', data=terr_data, palette='hot', \n",
    "                 colors_plot2=['crimson', 'gold'], color_lineplot='crimson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T20:06:58.786676Z",
     "start_time": "2019-09-04T20:06:41.658Z"
    }
   },
   "outputs": [],
   "source": [
    "country_analysis(country_name='Egypt', data=terr_data, palette='copper', \n",
    "                 colors_plot2=['crimson', 'brown'], color_lineplot='brown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope you really enjoy this storytelling. Please upvote this kernel to keep me motivated to do even more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not the final version. There is much more to do:\n",
    "\n",
    "* Incidents that lasted more than 24h (extended = 1);\n",
    "* Major radical groups responsible for terrorist attacks (gname);\n",
    "* Attacks with the highest number of terrorists (nperps);\n",
    "* Create a WordCloud for attributes like summary corp1, target1 and motive;\n",
    "* See wordclouds over the years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://nbviewer.jupyter.org/gist/jtbaker/57a37a14b90feeab7c67a687c398142c?flush_cache=true\n",
    "\n",
    "https://github.com/python-visualization/folium/issues/904\n",
    "\n",
    "https://towardsdatascience.com/data-101s-spatial-visualizations-and-analysis-in-python-with-folium-39730da2adf\n",
    "\n",
    "https://www.kaggle.com/rachan/how-to-folium-for-maps-heatmaps-time-analysis\n",
    "\n",
    "https://python-visualization.github.io/folium/plugins.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
